{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2 - Procesamiento distribuido y redes neuronales profundas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Carga y transformacion de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c743796bd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "from skimage import transform\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import random_split, DataLoader, Sampler, SubsetRandomSampler,RandomSampler   \n",
    "from torchvision.datasets import DatasetFolder\n",
    "# Path del directorio\n",
    "path_dir = os.getcwd()\n",
    "# Se asigna un valor de reproductibilidad\n",
    "torch.manual_seed(6202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción de función loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de carga de imagenes de PIL \n",
    "def pil_loader(path):\n",
    "    \"\"\" Entrega una imagen en formato PIL a \n",
    "    partir de un path.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    path: str  \n",
    "        path del origen de la imagen \n",
    "    Returns:\n",
    "        Imagen PIL RGB \n",
    "    \"\"\"\n",
    "    img = Image.open(path)    \n",
    "    if img.mode == 'L':\n",
    "        tensor = transforms.ToTensor()(img)\n",
    "        tensor_RGB = torch.cat((tensor, tensor, tensor), 0)\n",
    "        return transforms.ToPILImage()(tensor_RGB) \n",
    "    else:\n",
    "        return img\n",
    "    \n",
    "# Funcion de carga de imagenes con skimage \n",
    "def skimage_loader(path):\n",
    "    \"\"\" Entrega una imagen en formato array a \n",
    "    partir de un path.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    path: str  \n",
    "        path del origen de la imagen \n",
    "    Returns:\n",
    "        Array de 3 canales compatible con skimage. \n",
    "    \"\"\"\n",
    "    img = skimage.io.imread(fname=(path))    \n",
    "    if len(img.shape) == 2:\n",
    "        img_reshape =  img.reshape((img.shape[0], img.shape[1],1))\n",
    "        img_3_canales = np.concatenate((img_reshape,img_reshape,img_reshape),axis=2)\n",
    "        return img_3_canales \n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para imagen Pil o array:\n",
    "# funcion para escalar a una imagen de 224x224\n",
    "def Transform_Resize(library = 'PyTorch'):\n",
    "    if library == 'PyTorch':\n",
    "        return transforms.Resize((224, 224))\n",
    "    elif library == 'skimage':\n",
    "        skimage_resize = lambda imagen: transform.resize(imagen, (224, 224))\n",
    "        return skimage_resize\n",
    "\n",
    "# funcion para voltear imagen con probabilidad 0.5\n",
    "def Transform_Flip(library = 'PyTorch'):\n",
    "    if library == 'PyTorch':\n",
    "        return transforms.RandomVerticalFlip(0.5)\n",
    "    elif library == 'skimage':\n",
    "        return lambda imagen: np.flipud(imagen) if (np.random.random()<0.5) else imagen\n",
    "    \n",
    "# Funcion para rotar la imagen con un angulo random entre (-20, 20) \n",
    "def Transform_Rotation(library = 'PyTorch'):\n",
    "    if library == 'PyTorch':\n",
    "        return transforms.RandomRotation((-20, 20))\n",
    "    elif library == 'skimage':\n",
    "        return lambda imagen: transform.rotate(imagen,(np.random.random()*40)-20,resize=False)\n",
    "    \n",
    "# Transformaciones para tensor:\n",
    "# funcion para escalar los valores del brillo de la imagen     \n",
    "def Transform_Scale(tensor, library = 'PyTorch'):\n",
    "    if library == 'PyTorch':\n",
    "        return torch.div(tensor, torch.max(tensor))\n",
    "    elif library == 'skimage':\n",
    "        return tensor / (np.max(tensor))\n",
    "\n",
    "def Transform_Mult(tensor, library = 'PyTorch'):\n",
    "    if library == 'PyTorch':\n",
    "        random_tensor = 0.3*torch.rand((3,224, 224)) + 1.2 \n",
    "        return torch.mul(tensor, random_tensor) \n",
    "    elif library == 'skimage':\n",
    "        random_array = (0.3*np.random.random_sample((224,224,3))) + 1.2 \n",
    "        return np.multiply(tensor, random_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listas de transformaciones\n",
    "transform_torchvision = transforms.Compose([Transform_Resize(),\n",
    "                                Transform_Flip(),\n",
    "                                Transform_Rotation(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Lambda(lambda x: Transform_Scale(x)),\n",
    "                                transforms.Lambda(lambda x: Transform_Mult(x))]) \n",
    "transform_skimage = transforms.Compose([Transform_Resize('skimage'),\n",
    "                                Transform_Flip('skimage'),\n",
    "                                Transform_Rotation('skimage'),\n",
    "                                transforms.Lambda(lambda x: Transform_Scale(x,'skimage')),\n",
    "                                transforms.Lambda(lambda x: Transform_Mult(x,'skimage')),\n",
    "                                transforms.ToTensor()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que entrega objetos data_set para train y test \n",
    "def loader(data_set_name, image_loader, transform):\n",
    "    if data_set_name == 'Train':\n",
    "        root_path = path_dir + '\\\\Data\\\\chest_xray\\\\train'\n",
    "        # Cargar el data_set train y el data_set test\n",
    "        data_set_train = DatasetFolder(root_path, image_loader,\n",
    "                                       extensions=('.jpeg', '.JPEG'),\n",
    "                                       transform = transform)\n",
    "        return data_set_train\n",
    "    elif data_set_name == 'Test':\n",
    "        root_path = path_dir + '\\\\Data\\\\chest_xray\\\\test'\n",
    "        # Cargar el data_set train y el data_set test\n",
    "        data_set_test = DatasetFolder(root_path, image_loader,\n",
    "                                       extensions=('.jpeg', '.JPEG'),\n",
    "                                       transform = transform)\n",
    "        return data_set_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar ambos, el data_set train y el data_set test\n",
    "data_set_train = loader('Train', skimage_loader, transform_skimage)\n",
    "data_test = loader('Test', skimage_loader, transform_skimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualización de distribución de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 451.875x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cantidad de muestras en train\n",
    "train_len = len(data_set_train)\n",
    "# Largos de data sets\n",
    "len_train_0 = len([data_set_train.samples[i][1] for i in range(len(data_set_train)) \n",
    "                   if (data_set_train.samples[i][1] == 0)])\n",
    "len_train_1 = len([data_set_train.samples[i][1] for i in range(len(data_set_train)) \n",
    "                   if (data_set_train.samples[i][1] == 1)])\n",
    "len_test_0 = len([data_test.samples[i][1] for i in range(len(data_test)) \n",
    "                   if (data_test.samples[i][1] == 0)])\n",
    "len_test_1 = len([data_test.samples[i][1] for i in range(len(data_test)) \n",
    "                   if (data_test.samples[i][1] == 1)])\n",
    "# plotear distribuciones de datos\n",
    "data_plot = {'Data set':  ['Train','Train','Test','Test'],\n",
    "        'Clase': ['Pneumonia','Normal','Pneumonia','Normal'],\n",
    "        'Cantidad de datos': [len_train_0,len_train_1,len_test_0,len_test_1]}\n",
    "df_plot = pd.DataFrame(data_plot, columns = ['Data set','Clase','Cantidad de datos'])\n",
    "# Plotear gráficos de barra\n",
    "sns.axes_style(\"darkgrid\")\n",
    "sns_plot = sns.catplot(x='Data set', y='Cantidad de datos', hue='Clase', data=df_plot, kind='bar')\n",
    "# sns_plot.savefig(\"Distribución de datos.png\",dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción de clase ReplicarMuestreoDePrueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = random_split(data_set_train, [int(train_len*0.8),\n",
    "                                                                 train_len - int(train_len*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplicarMuestreoDePrueba(Sampler):\n",
    "    def __init__(self, etiquetas_prueba, indices_val, etiquetas_val):\n",
    "        self.etiquetas_prueba = etiquetas_prueba\n",
    "        self.indices_val = indices_val \n",
    "        self.etiquetas_val = etiquetas_val\n",
    "        self.indices_val_iter = indices_val \n",
    "        self.val_prob_normal = etiquetas_val.count(0)/len(etiquetas_val)\n",
    "        self.val_prob_pneumo = etiquetas_val.count(1)/len(etiquetas_val)\n",
    "        self.test_prob_normal = etiquetas_prueba.count(0)/len(etiquetas_prueba)\n",
    "        self.test_prob_pneumo = etiquetas_prueba.count(1)/len(etiquetas_prueba)\n",
    "    def __iter__(self):\n",
    "        if self.val_prob_pneumo <= self.test_prob_pneumo:\n",
    "            # etiquetas pneumo a agregar\n",
    "            plus = SubsetRandomSampler(((len(self.etiquetas_val)*self.test_prob_pneumo)\n",
    "                        -self.etiquetas_val.count(1))/(1-self.test_prob_pneumo))\n",
    "            # Agregar 'plus' indices de neumonia uniforme  \n",
    "            indices_val_pneumo = [self.indices_val[i] for i in range(len(self.indices_val)) \n",
    "                                  if self.etiquetas_val[i] == 1]\n",
    "            # Append    \n",
    "            index_plus = np.random.choice(indices_val_pneumo, plus, replace=True)\n",
    "        else:\n",
    "            # agregar normal al neumos\n",
    "            plus = int(((len(self.etiquetas_val)*self.test_prob_normal)\n",
    "                        -self.etiquetas_val.count(0))/(1-self.test_prob_normal))\n",
    "            # Agregar 'plus' indices de normal uniforme  \n",
    "            indices_val_normal = [self.indices_val[i] for i in range(len(self.indices_val)) \n",
    "                                  if self.etiquetas_val[i] == 0]\n",
    "            # Append\n",
    "            index_plus = np.random.choice(indices_val_normal, plus, replace=True)\n",
    "        return iter(self.indices_val_iter + list(index_plus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_prueba = data_test.targets\n",
    "indices_val = data_valid.indices\n",
    "etiquetas_val = [data_set_train.targets[i] for i in data_valid.indices] \n",
    "# inicializar iterator para valid\n",
    "RMP = ReplicarMuestreoDePrueba(etiquetas_prueba, indices_val, etiquetas_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "loader_data_train = DataLoader(data_set_train, batch_size=batch_size,\n",
    "                               sampler= SubsetRandomSampler(data_train.indices))\n",
    "loader_data_valid = DataLoader(data_set_train, batch_size=batch_size, sampler=RMP)\n",
    "loader_data_test = DataLoader(data_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba de tiempo\n",
    "def unpacking_dataloader(data_loader, n):\n",
    "    for i_batch, sample_batched in enumerate(data_loader):\n",
    "        if i_batch == n:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets con skimage y tochvision\n",
    "data_set_skimage = loader('Train', skimage_loader, transform_skimage)\n",
    "data_set_torchvision = loader('Train', pil_loader, transform_torchvision)\n",
    "# dataloader con skimage y dataloader con tochvision\n",
    "batch_size = 5\n",
    "loader_data_skimage = DataLoader(data_set_skimage, batch_size=batch_size, shuffle=True)\n",
    "loader_data_torchvision = DataLoader(data_set_torchvision, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiempo de carga total para loader_data_skimage \n",
    "# %prun unpacking_dataloader(loader_data_skimage,0)\n",
    "# 7676 function calls (7578 primitive calls) in 0.912 seconds\n",
    "# 10    0.325    0.032    0.325    0.032 {built-in method scipy.ndimage._nd_image.correlate1d}\n",
    "# Tiempo de carga total para loader_data_torchvision \n",
    "# %prun unpacking_dataloader(loader_data_torchvision,0)\n",
    "# 2354 function calls (2351 primitive calls) in 0.486 seconds\n",
    "#  163    0.214    0.001    0.214    0.001 {method 'read' of '_io.BufferedReader' objects}\n",
    "# probar con una imagen \n",
    "path = path_dir + '\\\\Data\\\\chest_xray\\\\train\\\\PNEUMONIA\\\\person1010_virus_1695.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# tiempo en cargar una imagen con pil\n",
    "%prun pil_loader(path)\n",
    "# 175 function calls in 0.012 seconds\n",
    "# 39    0.010    0.000    0.010    0.000 {method 'read' of '_io.BufferedReader' objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "# tiempo en cargar una imagen con skimage\n",
    "%prun skimage_loader(path)\n",
    "# 684 function calls in 0.006 seconds\n",
    "# 1    0.002    0.002    0.002    0.002 {method 'decode' of 'ImagingDecoder' objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform_Resize time\n",
    "pil_image = pil_loader(path)\n",
    "skimage_image = skimage_loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Resize(library = 'PyTorch')(pil_image)\n",
    "# 50 function calls in 0.005 seconds\n",
    "# 1    0.002    0.002    0.002    0.002 {method 'decode' of 'ImagingDecoder' objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Resize(library = 'skimage')(skimage_image)\n",
    "# 541 function calls (526 primitive calls) in 0.020 seconds\n",
    "# 1    0.008    0.008    0.015    0.015 _warps.py:666(warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform_Resize time\n",
    "pil_image = Transform_Resize(library = 'PyTorch')(pil_image)\n",
    "skimage_image = Transform_Resize(library = 'skimage')(skimage_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Flip(library = 'PyTorch')(pil_image)\n",
    "# 17 function calls in 0.000 seconds\n",
    "# 1    0.000    0.000    0.000    0.000 {built-in method builtins.exec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Flip(library = 'skimage')(skimage_image)\n",
    "# 12 function calls in 0.000 seconds\n",
    "# 1    0.000    0.000    0.000    0.000 <ipython-input-25-3e18e36632c1>:15(<lambda>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform_Flip time\n",
    "pil_image = Transform_Flip(library = 'PyTorch')(pil_image)\n",
    "skimage_image = Transform_Flip(library = 'skimage')(skimage_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Rotation(library = 'PyTorch')(pil_image)\n",
    "# 63 function calls in 0.001 seconds\n",
    "# 1    0.000    0.000    0.000    0.000 {built-in method PIL._imaging.fill}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Rotation(library = 'skimage')(skimage_image)\n",
    "# 154 function calls (150 primitive calls) in 0.014 seconds\n",
    "# 1    0.009    0.009    0.014    0.014 _warps.py:666(warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform_Flip time\n",
    "pil_image = Transform_Rotation(library = 'PyTorch')(pil_image)\n",
    "skimage_image = Transform_Rotation(library = 'skimage')(skimage_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagen a tensor\n",
    "pil_image = transforms.ToTensor()(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Scale(pil_image, library = 'PyTorch')\n",
    "# 6 function calls in 0.001 seconds\n",
    "# 1    0.001    0.001    0.001    0.001 {built-in method max}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Scale(skimage_image, library = 'skimage')\n",
    "# 12 function calls in 0.001 seconds\n",
    "# 1    0.001    0.001    0.001    0.001 <ipython-input-25-3e18e36632c1>:26(Transform_Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform_Flip time\n",
    "pil_image = Transform_Scale(pil_image, library = 'PyTorch')\n",
    "skimage_image = Transform_Scale(skimage_image, library = 'skimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Mult(pil_image, library = 'PyTorch')\n",
    "# 6 function calls in 0.002 seconds\n",
    "# 1    0.001    0.001    0.001    0.001 {built-in method rand}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun Transform_Mult(skimage_image, library = 'skimage')\n",
    "# 5 function calls in 0.005 seconds\n",
    "# 1    0.002    0.002    0.004    0.004 <ipython-input-25-3e18e36632c1>:32(Transform_Mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
